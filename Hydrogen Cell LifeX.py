import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import io
import webbrowser

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œå›¾æ ‡
st.set_page_config(page_title="HydrogenCell LifeX",
                   page_icon="./photo/é¡¶éƒ¨æ .png",
                   # layout="wide",
                   initial_sidebar_state="expanded"
                   )
# æ˜¾ç¤º Logo
st.sidebar.image("./photo/logo.png", width=200)
# ä¾§è¾¹æ 
import base64
def image_to_base64(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()
your_base64_logo = image_to_base64("./photo/é¡¶éƒ¨æ .png")
st.sidebar.markdown(
    f"""
    <div style="display: flex; align-items: center;">
        <img src="data:image/png;base64,{your_base64_logo}" width="30"/>
        <span style="font-size: 27px; font-weight: bold; margin-left: 10px;">HydrogenCell LifeX</span>
    </div>
    """,
    unsafe_allow_html=True,
)

# åˆå§‹åŒ– session_state
if "page" not in st.session_state:
    st.session_state.page = "ğŸ  Home"  # é»˜è®¤é¡µé¢
# æ·»åŠ è‡ªå®šä¹‰ CSS æ¥æ”¾å¤§æŒ‰é’®
st.markdown(
    """
    <style>
        div.stButton > button {
            width: 100%; 
            height: 50px; 
            font-size: 25px;
            background-color: #f0f2f6;  
            font-weight: bold;  /* åŠ ç²— */
            border-radius: 20px;  /* åœ†è§’æŒ‰é’® */
            border: none;
        }
        /* æ‚¬åœæ•ˆæœ*/
        div.stButton > button:hover {
            background-color: #e3e5e7;  /* æ‚¬åœæ—¶å˜æ·± */
            opacity: 0.85;  /* è½»å¾®é€æ˜åº¦å˜åŒ– */
            color: initial !important;
        }   
        /* è¢«ç‚¹å‡»æ—¶çš„æ•ˆæœ */
        div.stButton > button:focus {
            background-color: #e3e5e7; /* ç‚¹å‡»æ—¶çš„èƒŒæ™¯é¢œè‰² */
            color: initial !important;
        }

    </style>
    """,
    unsafe_allow_html=True
)
st.markdown(
    """
    <style>
        .appview-container {
            background-color: #f9f9f9;  /* è¿™é‡Œæ¢æˆä½ æƒ³è¦çš„é¢œè‰² */
        }
        header {
            background-color: #f9f9f9!  important; /* è¿™é‡Œæ¢æˆä½ æƒ³è¦çš„é¢œè‰² */
        }
    </style>
    """,
    unsafe_allow_html=True
)
# ä¾§è¾¹æ æŒ‰é’®
if st.sidebar.button("ğŸ  Home"):
    st.session_state.page = "ğŸ  Home"

if st.sidebar.button("âš™ï¸ åŠŸèƒ½"):
    st.session_state.page = "âš™ï¸ åŠŸèƒ½"


# é¦–é¡µå†…å®¹
if st.session_state.page == "ğŸ  Home":

    # è‡ªå®šä¹‰ CSS æ ·å¼ï¼Œè®¾ç½®å›¾ç‰‡å’Œæ ‡é¢˜å±…ä¸­
    css = """
    <style>
        /* ä½¿æ ‡é¢˜å±…ä¸­ */
        h1 {
            text-align: center;
            font-size: 30px;
        }
    </style>
    """
    # åº”ç”¨è‡ªå®šä¹‰ CSS æ ·å¼
    st.markdown(css, unsafe_allow_html=True)
    st.image("./photo/å›¾ç‰‡1.png", width=200)  # æ›¿æ¢ä¸ºä½ çš„LOGOè·¯å¾„
    st.title("HydrogenCell LifeX")

    st.write("""
        **æ¬¢è¿ä½¿ç”¨HydrogenCell LifeXï¼**  
                       
        æœ¬è½¯ä»¶æ˜¯ä¸€ç§åŸºäºé™ç»´åˆ†ç±»çš„æ°¢ç‡ƒæ–™ç”µæ± å¯¿å‘½é¢„æµ‹è½¯ä»¶ï¼Œæ—¨åœ¨è§£å†³ç›®å‰æ°¢ç‡ƒæ–™ç”µæ± å¯¿å‘½é¢„æµ‹é¢†åŸŸå•ä¸€æ¨¡å‹å¯¹å¤æ‚å¤šå˜å·¥å†µæ•°æ®é¢„æµ‹èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ã€‚æ¨¡å‹æ€è·¯ï¼šé¦–å…ˆé€šè¿‡PCAé™ç»´å¤„ç†ä¸åŒçš„æ•°æ®é›†ï¼Œå½¢æˆä¸€ä¸ªç»¼åˆçš„ç›¸ä¼¼æ€§å›¾è°±ã€‚é€šè¿‡è¿™ä¸ªå›¾è°±ï¼Œæˆ‘ä»¬å¯ä»¥æ¸…æ™°åœ°è¯†åˆ«å‡ºä¸åŒå·¥å†µä¸‹çš„æ°¢ç‡ƒæ–™ç”µæ± çš„ç‰¹å¾è¡¨ç°ï¼Œå¹¶è¿›ä¸€æ­¥æ¯”è¾ƒå®ƒä»¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œå½“å¼•å…¥æ–°çš„æ•°æ®æ—¶ï¼Œç³»ç»Ÿå¯ä»¥é€šè¿‡ä¸å·²æœ‰å›¾è°±è¿›è¡Œæ¯”å¯¹ï¼Œæ‰¾åˆ°ä¸æ–°æ•°æ®æœ€ä¸ºç›¸ä¼¼çš„å·¥å†µï¼Œå¹¶ä½¿ç”¨å¯¹åº”çš„æ•°æ®é›†æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚
            
        ç›®å‰ï¼Œæˆ‘ä»¬å·²ç»æ”¶é›†äº†ä¸‰ç»„æ•°æ®é›†è¿›è¡Œè¿›è¡Œé™ç»´ï¼Œå½¢æˆä¸€ä¸ªç›¸ä¼¼æ€§å›¾è°±ã€‚ç»è¿‡åˆæ­¥æµ‹è¯•ï¼Œæ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„é¢„æµ‹ç»“æœè¡¨ç°è‰¯å¥½ï¼ŒéªŒè¯äº†æˆ‘ä»¬çš„æ€è·¯å’Œæ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚
    """)

    st.write("""
        **HydrogenCell LifeåŠŸèƒ½ä»‹ç»ï¼**  
        - **åŠŸèƒ½åŒº**ï¼š åŠŸèƒ½åŒºæä¾›äº†ä¸€æ–‡ä»¶ä¸Šä¼ çš„æŒ‰é’®
        - **ç®±çº¿å›¾åˆ†æ**ï¼šç”¨äºå¯è§†åŒ–ä¸Šä¼ çš„æ–°æ•°æ®æ•°æ®åˆ†å¸ƒæƒ…å†µ  
        - **PCAé™ç»´ç›¸ä¼¼æ€§åˆ†æ**ï¼šå¯¹æ–°æ•°æ®è¿›è¡Œé™ç»´ï¼Œå†é€šè¿‡ä¸å·²æœ‰å›¾è°±è¿›è¡Œæ¯”å¯¹ï¼Œæ‰¾åˆ°ä¸æ–°æ•°æ®æœ€ä¸ºç›¸ä¼¼çš„å·¥å†µ
        - **æ¨¡å‹é¢„æµ‹ç»“æœåˆ†æ**ï¼šä½¿ç”¨å¯¹åº”æ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        è¯·åœ¨å·¦ä¾§é€‰æ‹©â€œåŠŸèƒ½â€ä»¥è¿›å…¥åˆ†æç•Œé¢ã€‚
    """)

    st.write("""
        **HydrogenCell Lifeçš„ä¸¾ä¾‹æ–‡ä»¶ï¼**  
        https://github.com/withand123/HydrogenCell-Life
    """)
    # åˆ›å»ºæŒ‰é’®

    # if st.button("ç‚¹å‡»æ‰“å¼€é“¾æ¥"):
    #     url = "https://numpy.org/"
    #     # å°è¯•æ‰“å¼€é“¾æ¥
    #     try:
    #         webbrowser.open_new_tab(url)
    #     except Exception as e:
    #         st.error(f"æ‰“å¼€é“¾æ¥æ—¶å‡ºç°é”™è¯¯: {e}")

# åŠŸèƒ½ç•Œé¢
elif st.session_state.page == "âš™ï¸ åŠŸèƒ½":
    if st.sidebar.button("ğŸ“Š ç®±çº¿å›¾åˆ†æ"):
        st.session_state.selected_function = "boxplot"

    if st.sidebar.button("ğŸ“‰ PCAé™ç»´ç›¸ä¼¼æ€§åˆ†æ"):
        st.session_state.selected_function = "pca"

    if st.sidebar.button("ğŸ” æ¨¡å‹é¢„æµ‹ç»“æœåˆ†æ"):
        st.session_state.selected_function = "model"
    # åˆå§‹åŒ– session_state
    if "selected_function" not in st.session_state:
        st.session_state.selected_function = None
    if "df" not in st.session_state:
        st.session_state.df = None
    # **åˆå§‹åŒ– session_state**
    if "fig1" not in st.session_state:
        st.session_state.fig1 = None  # å­˜å‚¨å½“å‰å›¾åƒ
    if "closest_dataset" not in st.session_state:
        st.session_state.closest_dataset = None


    # æ˜¾ç¤º Logo
    st.image("./photo/å›¾ç‰‡1.png", width=200)
    # é¡µé¢æ ‡é¢˜
    st.title("Hydrogen Cell LifeX")
    # è‡ªå®šä¹‰é¡µé¢æ ·å¼
    st.markdown("""
        <style>
        .reportview-container {
            background-color: #f5f5f5;  /* è®¾ç½®é¡µé¢èƒŒæ™¯è‰² */
        }
        .sidebar .sidebar-content {
            background-color: #2f2f2f;  /* è®¾ç½®ä¾§è¾¹æ èƒŒæ™¯è‰² */
            color: white;               /* è®¾ç½®ä¾§è¾¹æ æ–‡æœ¬é¢œè‰² */
        }
        .css-1n6gftb {  /* é’ˆå¯¹æŒ‰é’®çš„æ ·å¼ */
            background-color: #ff5733 !important;  /* è®¾ç½®æŒ‰é’®èƒŒæ™¯è‰² */
            color: white !important;               /* è®¾ç½®æŒ‰é’®æ–‡å­—é¢œè‰² */
            font-size: 16px !important;            /* è®¾ç½®æŒ‰é’®å­—ä½“å¤§å° */
            border-radius: 10px !important;        /* è®¾ç½®æŒ‰é’®åœ†è§’ */
        }
        </style>
        """, unsafe_allow_html=True)
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("é€‰æ‹©æ–‡ä»¶", type=["csv", "xlsx"])

    if uploaded_file is not None:
        file_name = uploaded_file.name
        if file_name.endswith(".csv"):
            st.session_state.df = pd.read_csv(uploaded_file, index_col=0)
        elif file_name.endswith(".xlsx"):
            st.session_state.df = pd.read_excel(uploaded_file, index_col=0)
        else:
            st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

        if st.session_state.df is not None:
            st.write("æ•°æ®é¢„è§ˆï¼š")
            st.dataframe(st.session_state.df)

    # ä¸»ç•Œé¢æ˜¾ç¤ºåŒº
    st.subheader("æ•°æ®å¯è§†åŒ–åŒºåŸŸ")

    # å¤„ç†ä¸åŒçš„åŠŸèƒ½
    if st.session_state.selected_function == "boxplot":
        st.write("### ç®±çº¿å›¾åˆ†æ")

        if st.session_state.df is not None:
            def xiangxian(data):
                # ç¡®ä¿æ•°æ®ä¸­åŒ…å« 'Time (h)' è¿™ä¸€åˆ—
                from matplotlib import pyplot as plt
                from pylab import mpl
                mpl.rcParams['font.sans-serif'] = ['SimHei']  # æŒ‡å®šé»˜è®¤å­—ä½“
                mpl.rcParams['axes.unicode_minus'] = False  # è´Ÿå·- æ˜¾ç¤ºæ–¹å—
                data.index = data.pop('Time (h)')
                # è®¾ç½®ç»˜å›¾é£æ ¼
                sns.set(style="whitegrid", font_scale=1.2)  # é€‚å½“å¢å¤§å­—ä½“æ¯”ä¾‹
                plt.rcParams['font.sans-serif'] = ['SimHei']
                # å®šä¹‰é¢œè‰²è°ƒè‰²æ¿
                palette = sns.color_palette("Set2")
                # åˆ›å»ºä¸€ä¸ªç”»å¸ƒï¼Œç»˜åˆ¶å¤§å›¾ç®±çº¿å›¾
                fig,ax = plt.subplots(figsize=(12, 6))  # è°ƒæ•´å¤§å›¾å°ºå¯¸
                ax = plt.gca()
                sns.boxplot(data=data, ax=ax, palette=palette)
                # ax_big.set_title('å˜é‡ç®±çº¿å›¾')
                ax.set_xlabel('å˜é‡')
                ax.set_ylabel('èŒƒå›´')
                ax.tick_params(axis='both', labelsize=12)  # è°ƒæ•´åˆ»åº¦æ ‡ç­¾å­—ä½“å¤§å°
                # è°ƒæ•´å¸ƒå±€å¹¶æ˜¾ç¤ºå›¾å½¢
                plt.tight_layout()

                st.session_state.fig1 = fig
                st.session_state.file_name = "boxplot.png"  # è®¾ç½®æ–‡ä»¶å
                st.pyplot(st.session_state.fig1)


                # å¼‚å¸¸å€¼å¤„ç†å‡½æ•°
                def count_outliers(dff):
                    outliers_count = {}
                    for column in dff.select_dtypes(include=['float64', 'int64']).columns:
                        Q1 = dff[column].quantile(0.25)
                        Q3 = dff[column].quantile(0.75)
                        IQR = Q3 - Q1
                        lower_bound_15 = Q1 - 1.5 * IQR
                        upper_bound_15 = Q3 + 1.5 * IQR
                        lower_bound_3 = Q1 - 3 * IQR
                        upper_bound_3 = Q3 + 3 * IQR

                        # æ¸©å’Œå¼‚å¸¸å€¼ï¼šè½åœ¨[lower_bound_3, lower_bound_15) æˆ– (upper_bound_15, upper_bound_3]
                        mild_outliers = dff[(dff[column] < lower_bound_15) & (dff[column] >= lower_bound_3) |
                                            (dff[column] > upper_bound_15) & (dff[column] <= upper_bound_3)]
                        # æç«¯å¼‚å¸¸å€¼ï¼šå°äº lower_bound_3 æˆ– å¤§äº upper_bound_3
                        extreme_outliers = dff[(dff[column] < lower_bound_3) | (dff[column] > upper_bound_3)]

                        outliers_count[column] = {
                            'mild': len(mild_outliers),
                            'extreme': len(extreme_outliers)
                        }
                    return outliers_count

                def process_outliers(dff):
                    outliers = count_outliers(dff)
                    processed_df = dff.copy()
                    for column in outliers.keys():
                        Q1 = dff[column].quantile(0.25)
                        Q3 = dff[column].quantile(0.75)
                        IQR = Q3 - Q1
                        lower_bound_3 = Q1 - 3 * IQR
                        upper_bound_3 = Q3 + 3 * IQR
                        # åˆ é™¤æç«¯å¼‚å¸¸å€¼
                        processed_df = processed_df[(processed_df[column] >= lower_bound_3) & (processed_df[column] <= upper_bound_3)]
                    return processed_df, outliers

                # å¤„ç†å¼‚å¸¸å€¼
                cleaned_data, outlier_stats = process_outliers(data)
                # æ˜¾ç¤ºå¼‚å¸¸å€¼ç»Ÿè®¡ä¿¡æ¯
                st.write("### å¼‚å¸¸å€¼ç»Ÿè®¡")
                st.write(pd.DataFrame(outlier_stats).T)

                # æ¢å¤æ—¶é—´åˆ—
                processed_data = cleaned_data.reset_index().rename(columns={'index': 'Time (h)'})
                # å°†å¤„ç†åçš„æ•°æ®ä¼ å› `st.session_state.df`
                st.session_state.df = processed_data

                # ç¡®è®¤æ•°æ®å·²æ›´æ–°
                st.success("å¼‚å¸¸å€¼å·²å¤„ç†ï¼Œæ•°æ®å·²æ›´æ–°ï¼")

            xiangxian(st.session_state.df)
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®ï¼")

    elif st.session_state.selected_function == "pca":
        st.write("### PCA é™ç»´ç›¸ä¼¼æ€§åˆ†æ")
        if st.session_state.df is not None:
            # PCAæ•ˆæœå±•ç°    åŠ å…¥ä¸€ä¸ªåˆ¤æ–­é ç»é‚£ä¸ªmodel
            def pca_effect(data4):
                from sklearn.decomposition import PCA
                from sklearn.preprocessing import StandardScaler
                # è¯»å…¥FC
                data1 = pd.read_csv('./FC_xiangxian.csv')
                # è¯»å…¥å›½å®¶æ•°æ®é›†
                data2 = pd.read_csv('./guojia_xiangxian.csv', index_col=0)
                # è¯»å…¥åŒæµå¤§å­¦æ•°æ®é›†
                data3 = pd.read_csv('./tongji_xiangxian.csv', index_col=0)
                columns = ['Time (h)', 'Utot (V)', 'I (A)', 'TinH2 (â„ƒ)', 'ToutH2 (â„ƒ)',
                           'TinAIR (â„ƒ)', 'PinH2 (Kpa)', 'PoutH2 (Kpa)', 'PinAIR (Kpa)']
                data1.columns = columns
                data2.columns = columns
                data3.columns = columns

                from matplotlib import pyplot as plt
                from pylab import mpl
                mpl.rcParams['font.sans-serif'] = ['SimHei']  # æŒ‡å®šé»˜è®¤å­—ä½“
                mpl.rcParams['axes.unicode_minus'] = False  # è´Ÿå·- æ˜¾ç¤ºæ–¹å—
                # åˆå¹¶æ•°æ®
                data = pd.concat([data1, data2, data3], ignore_index=True)

                # ä¸ºæ¯ä¸ªæ•°æ®é›†åˆ›å»ºä¸€ä¸ªæ ‡ç­¾
                labels = ['FCæ•°æ®é›†'] * len(data1) + ['å›½å®¶æ•°æ®ä¸­å¿ƒæ•°æ®é›†'] * len(data2) + ['åŒæµå¤§å­¦æ•°æ®é›†'] * len(data3)

                # æ•°æ®æ ‡å‡†åŒ–
                scaler = StandardScaler()
                data_scaled = scaler.fit_transform(data)

                # åº”ç”¨PCA
                pca = PCA(n_components=2)
                data_pca = pca.fit_transform(data_scaled)

                # è·å–è§£é‡Šæ–¹å·®æ¯”
                explained_variance_ratio = pca.explained_variance_ratio_

                # å®šä¹‰é¢œè‰²æ˜ å°„
                colors = {'FCæ•°æ®é›†': 'red', 'å›½å®¶æ•°æ®ä¸­å¿ƒæ•°æ®é›†': 'blue', 'åŒæµå¤§å­¦æ•°æ®é›†': 'green'}

                data_scaled4 = scaler.transform(data4)
                # ä½¿ç”¨ç›¸åŒçš„PCAæ¨¡å‹å¯¹æ–°æ•°æ®è¿›è¡Œå˜æ¢
                new_pca_result4 = pca.transform(data_scaled4)
                import numpy as np
                # å¯è§†åŒ–
                fig,ax = plt.subplots(figsize=(10, 8))
                for label in set(labels):
                    mask = np.array(labels) == label
                    plt.scatter(data_pca[mask, 0], data_pca[mask, 1], color=colors[label], label=label)
                labels1 = ['æ–°æ•°æ®é›†1'] * len(data4)
                mask1 = np.array(labels1) == 'æ–°æ•°æ®é›†1'
                plt.scatter(new_pca_result4[mask1, 0], new_pca_result4[mask1, 1], label='æ–°æ•°æ®é›†1')
                plt.xlabel(f"PC1 ({explained_variance_ratio[0] * 100:.2f}%)", fontsize=12)
                plt.ylabel(f"PC2 ({explained_variance_ratio[1] * 100:.2f}%)", fontsize=12)
                # plt.xlabel('ä¸»æˆåˆ†åˆ†æ1', fontsize=12)
                # plt.ylabel('ä¸»æˆåˆ†åˆ†æ2', fontsize=12)
                # plt.title("åŸºäºä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰çš„ç›¸ä¼¼æ€§å›¾è°±", fontsize=16)
                plt.legend(prop={'size': 12})

                st.session_state.fig1 = fig
                st.session_state.file_name = "pca_plot.png"  # è®¾ç½®æ–‡ä»¶å
                st.pyplot(st.session_state.fig1)

                # è®¡ç®—data4ä¸å„ä¸ªæ•°æ®é›†çš„å¹³å‡è·ç¦»
                # å°†æ•°æ®é›†åˆ†ç»„
                fc_mask = np.array(labels) == 'FCæ•°æ®é›†'
                guojia_mask = np.array(labels) == 'å›½å®¶æ•°æ®ä¸­å¿ƒæ•°æ®é›†'
                tongji_mask = np.array(labels) == 'åŒæµå¤§å­¦æ•°æ®é›†'

                # è®¡ç®—æ¯ä¸ªæ•°æ®é›†åœ¨PCAç©ºé—´ä¸­çš„è´¨å¿ƒ
                fc_centroid = np.mean(data_pca[fc_mask], axis=0)
                guojia_centroid = np.mean(data_pca[guojia_mask], axis=0)
                tongji_centroid = np.mean(data_pca[tongji_mask], axis=0)

                # è®¡ç®—data4åœ¨PCAç©ºé—´ä¸­çš„è´¨å¿ƒ
                data4_centroid = np.mean(new_pca_result4, axis=0)

                # è®¡ç®—ä¸å„ä¸ªæ•°æ®é›†è´¨å¿ƒçš„æ¬§æ°è·ç¦»
                dist_to_fc = np.linalg.norm(data4_centroid - fc_centroid)
                dist_to_guojia = np.linalg.norm(data4_centroid - guojia_centroid)
                dist_to_tongji = np.linalg.norm(data4_centroid - tongji_centroid)

                # æ‰¾å‡ºæœ€è¿‘çš„æ•°æ®é›†
                distances = {
                    'FCæ•°æ®é›†': dist_to_fc,
                    'å›½å®¶æ•°æ®ä¸­å¿ƒæ•°æ®é›†': dist_to_guojia,
                    'åŒæµå¤§å­¦æ•°æ®é›†': dist_to_tongji
                }

                st.session_state.closest_dataset = min(distances, key=distances.get)
                # ç¡®è®¤æ•°æ®å·²æ›´æ–°
                st.success(f"è¯¥æ•°æ®é›†é è¿‘{st.session_state.closest_dataset}ï¼")

            pca_effect(st.session_state.df)
        else:
            st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®ï¼")
    elif st.session_state.selected_function == "model":
        st.write("### æ¨¡å‹é¢„æµ‹ç»“æœåˆ†æ")
        if st.session_state.closest_dataset is not None:
            # æ¨¡å‹é¢„æµ‹æ•ˆæœ
            def model_effect(closest_dataset):
                import pandas as pd
                import numpy as np
                from keras.models import load_model
                # æ ¹æ®closest_datasetåˆ¤æ–­ä½¿ç”¨å“ªä¸ªæ¨¡å‹
                if closest_dataset == 'FCæ•°æ®é›†':
                    model = load_model('./model/FC_LSTM_KAN.keras', safe_mode=False)
                    data = pd.read_csv('./sampled_FC.csv', index_col=0)
                    columns = ['Time (h)', 'Utot (V)', 'I (A)', 'TinH2 (â„ƒ)', 'ToutH2 (â„ƒ)',
                               'TinAIR (â„ƒ)', 'PinH2 (Kpa)', 'PoutH2 (Kpa)', 'PinAIR (Kpa)']
                    data.columns = columns
                elif closest_dataset == 'å›½å®¶æ•°æ®ä¸­å¿ƒæ•°æ®é›†':
                    model = load_model('./model/guojia_LSTM_KAN.keras', safe_mode=False)
                    data = pd.read_csv('./sampled_guojia.csv', index_col=0)
                    columns = ['Time (h)', 'Utot (V)', 'I (A)', 'TinH2 (â„ƒ)', 'ToutH2 (â„ƒ)',
                               'TinAIR (â„ƒ)', 'PinH2 (Kpa)', 'PoutH2 (Kpa)', 'PinAIR (Kpa)']
                    data.columns = columns
                elif closest_dataset == 'åŒæµå¤§å­¦æ•°æ®é›†':
                    model = load_model('./model/tongji_LSTM_KAN.keras', safe_mode=False)
                    data = pd.read_csv('./tongji_sampled.csv', index_col=0)
                    columns = ['Time (h)', 'Utot (V)', 'I (A)', 'TinH2 (â„ƒ)', 'ToutH2 (â„ƒ)',
                               'TinAIR (â„ƒ)', 'PinH2 (Kpa)', 'PoutH2 (Kpa)', 'PinAIR (Kpa)']
                    data.columns = columns
                data.index = data.pop('Time (h)')
                split_index = int(np.floor(len(data) * 0.6))
                train_data = data.iloc[:split_index]
                test_data = data.iloc[split_index:]
                from sklearn import preprocessing
                min_max_scalar = preprocessing.MinMaxScaler()
                data_for_training_scaled = min_max_scalar.fit_transform(train_data)
                step = 1
                ahead = 1

                def createXY(dataset, n_pase, step_ahead):
                    dataX = []
                    dataY = []
                    for i in range(n_pase, len(dataset) - step_ahead):
                        dataX.append(dataset[i - n_pase:i, 0:dataset.shape[1]])
                        dataY.append(dataset[i + step_ahead, 0])
                    return np.array(dataX), np.array(dataY)

                # è¯»å…¥æ–°æ•°æ®
                sampled_data1 = pd.read_csv('generated_df7.csv', index_col=0)
                # ç”Ÿæˆä» 1 åˆ° 1000H çš„æ—¶é—´æ ‡ç­¾
                time_labels = [f'{i}' for i in range(1, len(sampled_data1) + 1)]
                # å°†æ—¶é—´åˆ—æ›¿æ¢ä¸ºæ–°çš„æ—¶é—´æ ‡ç­¾
                sampled_data1['Time (h)'] = time_labels
                data_1 = pd.read_csv('new_data7.csv', index_col=0)
                import statsmodels.api as sm
                # è®¾ç½® LOESS å¹³æ»‘çš„å‚æ•°
                window_width = 20
                window_width1 = 25
                import matplotlib.pyplot as plt
                from pylab import mpl
                import seaborn as sns
                mpl.rcParams['font.sans-serif'] = ['SimHei']  # æŒ‡å®šé»˜è®¤å­—ä½“
                mpl.rcParams['axes.unicode_minus'] = False  # è´Ÿå·- æ˜¾ç¤ºæ–¹å—
                # plt.figure(figsize=(10, 5))
                # plt.plot(data_1['Time (h)'], data_1['Utot (V)'], label='åŸå§‹æ•°æ®', alpha=0.7, color='red')
                # plt.plot(sampled_data1['Time (h)'], sampled_data1['Utot (V)'], label='é‡æ„æ•°æ®', alpha=0.7, color='blue')
                # ä½¿ç”¨ LOESS å¹³æ»‘æ•°æ®
                lowess = sm.nonparametric.lowess(sampled_data1['Utot (V)'], sampled_data1['Time (h)'],
                                                 frac=window_width / len(sampled_data1))
                lowess1 = sm.nonparametric.lowess(sampled_data1['I (A)'], sampled_data1['Time (h)'],
                                                  frac=window_width1 / len(sampled_data1))
                lowess2 = sm.nonparametric.lowess(sampled_data1['PoutH2 (Kpa)'], sampled_data1['Time (h)'],
                                                  frac=window_width1 / len(sampled_data1))
                # plt.plot(lowess[:, 0], lowess[:, 1], color='#00FF00', label='å¹³æ»‘æ•°æ®')
                # plt.xlabel('æ—¶é—´(h)', fontsize = 10)
                # plt.ylabel('ç”µå †ç”µå‹(V)', fontsize = 10)
                # plt.ylim(3.05, 3.4)
                # plt.legend()
                # plt.show()
                sampled_data1['I (A)'] = lowess1[:, 1]
                sampled_data1['Utot (V)'] = lowess[:, 1]
                sampled_data1['PoutH2 (Kpa)'] = lowess2[:, 1]
                sampled_data1.index = sampled_data1.pop('Time (h)')
                data_for_testing_scaled1 = min_max_scalar.transform(sampled_data1)
                tryX, tryY = createXY(data_for_testing_scaled1, step, ahead)
                prediction_try = model.predict(tryX)
                prediction_copied_array_try = np.repeat(prediction_try, 8, axis=-1)
                pred_try = min_max_scalar.inverse_transform(np.reshape(prediction_copied_array_try, (len(prediction_try), 8)))[
                           :, 0]
                original_copies_array_try = np.repeat(tryY, 8, axis=-1)
                original_try = min_max_scalar.inverse_transform(np.reshape(original_copies_array_try, (len(tryY), 8)))[:, 0]
                # data_time = train.index[-len(original):]
                data_time_try = len(original_try)
                from matplotlib import pyplot as plt
                from pylab import mpl
                mpl.rcParams['font.sans-serif'] = ['SimHei']  # æŒ‡å®šé»˜è®¤å­—ä½“
                mpl.rcParams['axes.unicode_minus'] = False  # è´Ÿå·- æ˜¾ç¤ºæ–¹å—
                from matplotlib import pyplot as plt
                fig, ax = plt.subplots(figsize=(12, 6))  # è°ƒæ•´å¤§å›¾å°ºå¯¸
                plt.plot(range(data_time_try), original_try, color='c', label='å®é™…å€¼')
                plt.plot(range(data_time_try), pred_try, color='red', label='FCæ•°æ®é›†æ¨¡å‹')
                plt.xlabel('å·¥ä½œæ—¶é—´(h)', fontsize=12)
                plt.ylabel('è¾“å‡ºç”µå‹(V)', fontsize=12)
                # plt.title('æµ‹è¯•é›†', fontsize = 12)
                # plt.ylim(-0.1, 0.2)
                # plt.ylim(0,0.10)
                plt.legend()

                st.session_state.fig1 = fig
                st.session_state.file_name = "model_prediction.png"  # è®¾ç½®æ–‡ä»¶å
                st.pyplot(fig)


                from sklearn import metrics
                import numpy as np
                # è¯„ä»·
                from sklearn.metrics import mean_squared_error, mean_absolute_error
                import math
                mse = mean_squared_error(np.array(pred_try), np.array(original_try))
                # calculate RMSE å‡æ–¹æ ¹è¯¯å·®--->sqrt[MSE]    (å¯¹å‡æ–¹è¯¯å·®å¼€æ–¹)
                rmse = math.sqrt(mean_squared_error(pred_try, original_try))
                # calculate MAE å¹³å‡ç»å¯¹è¯¯å·®----->E[|é¢„æµ‹å€¼-çœŸå®å€¼|](é¢„æµ‹å€¼å‡çœŸå®å€¼æ±‚ç»å¯¹å€¼åæ±‚å‡å€¼ï¼‰
                mae = mean_absolute_error(pred_try, original_try)

                def mape(actual_arr, pred_arr):
                    mask = np.abs(actual_arr) > 0.001
                    actual_arr = actual_arr[mask]
                    pred_arr = pred_arr[mask]
                    mape = np.mean(abs(((actual_arr - pred_arr) / actual_arr)))
                    return mape
                mape = mape(original_try, pred_try)
                st.write('å†³å®šç³»æ•°R2: %.6f' % metrics.r2_score(original_try, pred_try))
                st.write('å‡æ–¹è¯¯å·®MSE: %.6f' % mse)
                st.write('å‡æ–¹æ ¹è¯¯å·®RMSE: %.6f' % rmse)
                st.write('å¹³å‡ç»å¯¹è¯¯å·®MAE: %.6f' % mae)
                st.write('å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®MAPE: %.6f' % mape)
            model_effect(st.session_state.closest_dataset)
        else:
            st.warning("è¯·å…ˆè¿›è¡ŒPCAé™ç»´ç›¸ä¼¼æ€§åˆ†æï¼")

    # **é€šç”¨å¯¼å‡ºæŒ‰é’®**
    if st.session_state.fig1 is not None:
        buffer = io.BytesIO()
        st.session_state.fig1.savefig(buffer, format="png")
        buffer.seek(0)

        st.download_button(
            label="ğŸ“¥ å¯¼å‡ºå›¾ç‰‡",
            data=buffer,
            file_name=st.session_state.file_name,
            mime="image/png"
        )
